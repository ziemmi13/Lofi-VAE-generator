{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a329471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\pretty_midi\\instrument.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from train import train\n",
    "from lofi_model import LofiModel\n",
    "from dataset import MidiDataset\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "from config import *\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dcb974",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ebbf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Setting up datasets and dataloaders...\n",
      "Finished setting up datasets and dataloaders.\n",
      "\n",
      "Starting training:\n",
      "The datset has 11 batches\n",
      "Epoch [1/10]\n",
      "Validation Loss: 23148.7168\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [2/10]\n",
      "Validation Loss: 19627.0967\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [3/10]\n",
      "Validation Loss: 16528.3884\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [4/10]\n",
      "Validation Loss: 13970.4014\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [5/10]\n",
      "Validation Loss: 11835.6060\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [6/10]\n",
      "Validation Loss: 9847.6718\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [7/10]\n",
      "Validation Loss: 8119.8318\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [8/10]\n",
      "Validation Loss: 6849.8760\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [9/10]\n",
      "Validation Loss: 5622.3441\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Epoch [10/10]\n",
      "Validation Loss: 4607.0543\n",
      "------------------------------------------------------------ \n",
      "\n",
      "Finished training!\n",
      "Saving the model to path: ./saved_models/multitrack LSTM-VAE.pth\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "    # Dataset setup\n",
    "    dataset_dir = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\\mini_dataset\"\n",
    "\n",
    "    # Model setup\n",
    "    model = LofiModel(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Train\n",
    "    train(model, \n",
    "          dataset_dir, \n",
    "          verbose=True, \n",
    "          model_save_path = \"./saved_models/multitrack LSTM-VAE.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c883c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LofiModel(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(640, 256, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (hidden_to_mu): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (hidden_to_logvar): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (latent_to_hidden): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (latent_to_cell): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (lstm): LSTM(640, 256, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (fc_out): Linear(in_features=256, out_features=640, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = LofiModel(device)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/multitrack LSTM-VAE.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cad895",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6fac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\\mini_dataset\"\n",
    "dataset = MidiDataset(dataset_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfda65cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed multi-instrument MIDI saved to reconstructions/3bdd2d228e8f074117c4d5b6b56c6dd5.mid-reconstructed.mid\n",
      "Reconstructed multi-instrument MIDI saved to reconstructions/c24989559d170135b9c6546d1d2df20b.mid-reconstructed.mid\n",
      "Reconstructed multi-instrument MIDI saved to reconstructions/d296522612f8211e4f9bc2d45952df46.mid-reconstructed.mid\n",
      "Reconstructed multi-instrument MIDI saved to reconstructions/97def5c535d69374db8c6d48fa232638.mid-reconstructed.mid\n",
      "Reconstructed multi-instrument MIDI saved to reconstructions/5a59acb9f6b867f57989301aed230db0.mid-reconstructed.mid\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    original_sequence_tensor, original_length_val, bpm, filename = dataset[i]\n",
    "    reconstructions = model.reconstruct(original_sequence_tensor, bpm, save_path=f\"reconstructions/{filename}-reconstructed.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db395df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\"\n",
    "dataset = MidiDataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e38cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sequence_tensor, original_length_val, bpm = dataset[10]\n",
    "original_sequence_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20235835",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_original_sequence, original_length_tensor = MidiDataset.collate_fn([(original_sequence_tensor, original_length_val)])\n",
    "padded_original_sequence = padded_original_sequence.to(device)\n",
    "padded_original_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_sample, _, _ = model(padded_original_sequence, original_length_tensor)\n",
    "reconstructed_sample = reconstructed_sample.squeeze()\n",
    "reconstructed_sample = torch.sigmoid(reconstructed_sample)\n",
    "reconstructed_sample[reconstructed_sample < 0.5] = 0\n",
    "reconstructed_sample[reconstructed_sample >= 0.5] = 1\n",
    "reconstructed_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_sample_T = reconstructed_sample.T\n",
    "reconstructed_sample_T.shape\n",
    "reconstructed_sample_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e016b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PrettyMIDI object\n",
    "midi = pretty_midi.PrettyMIDI()\n",
    "piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "piano = pretty_midi.Instrument(program=piano_program)\n",
    "\n",
    "# Track note on/off times per pitch\n",
    "# We'll detect note start and end by scanning through time steps\n",
    "for pitch_idx in range(reconstructed_sample_T.shape[0]):\n",
    "    note_on = None\n",
    "    for t in range(reconstructed_sample_T.shape[1]):\n",
    "        if reconstructed_sample_T[pitch_idx, t] == 1 and note_on is None:\n",
    "            # Note on at time t/fs seconds\n",
    "            note_on = t / FS\n",
    "        elif (reconstructed_sample_T[pitch_idx, t] == 0 or t == reconstructed_sample_T.shape[0]-1) and note_on is not None:\n",
    "            # Note off at time t/fs seconds\n",
    "            note_off = t / FS\n",
    "            # Add the note to the instrument\n",
    "            note = pretty_midi.Note(    \n",
    "                velocity=50,\n",
    "                pitch= pitch_idx+MIN_MIDI_NOTE,\n",
    "                start=note_on,\n",
    "                end=note_off\n",
    "            )\n",
    "            piano.notes.append(note)\n",
    "            note_on = None  # reset for next note\n",
    "\n",
    "    # If a note is still on at the end, close it\n",
    "    if note_on is not None:\n",
    "        note_off = reconstructed_sample_T.shape[1] / FS\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=50,\n",
    "            pitch= pitch_idx+MIN_MIDI_NOTE,\n",
    "            start=note_on,\n",
    "            end=note_off\n",
    "        )\n",
    "        piano.notes.append(note)\n",
    "\n",
    "# Add instrument to the PrettyMIDI object\n",
    "midi.instruments.append(piano)\n",
    "\n",
    "# Write out the MIDI data\n",
    "midi.write(\"1 4 6 5 - chord progression-RECONSTRUCTION.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ae2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a001b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3a6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c328b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d0e1618",
   "metadata": {},
   "source": [
    "# CHORD EXTRACTOR DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter\n",
    "\n",
    "midi_pth = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\\1 2 6 - chord progression.mid\"\n",
    "midi_file = converter.parse(midi_pth)\n",
    "\n",
    "chords = midi_file.chordify()\n",
    "\n",
    "chord_progression = []\n",
    "\n",
    "for c in chords.flat.getElementsByClass(\"Chord\"):\n",
    "    if not c.isRest:\n",
    "        root_note = c.root().name\n",
    "        quality = c.quality\n",
    "        full_chord_name = c.pitchedCommonName\n",
    "        offset = c.offset  \n",
    "\n",
    "        chord_progression.append([root_note, quality, full_chord_name, offset])\n",
    "\n",
    "chord_progression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.load(\"../midi/98f90636c139256f4b7dade28ab87088.npz\")\n",
    "print(array)\n",
    "for a in array.keys():\n",
    "    print(a)\n",
    "    print(array[a])\n",
    "    print(20*\"___\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_all_tracks_from_npz(npz_path):\n",
    "    \"\"\"\n",
    "    Load all sparse pianoroll tracks from an LPD .npz file into dense arrays.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, np.ndarray]: Mapping from track_id to dense pianoroll (shape: time x pitch)\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    tracks = {}\n",
    "\n",
    "    for key in data.files:\n",
    "        if key.endswith(\"_csc_shape\"):\n",
    "            track_id = int(key.split(\"_\")[1])\n",
    "            shape = data[f\"pianoroll_{track_id}_csc_shape\"]\n",
    "            indptr = data[f\"pianoroll_{track_id}_csc_indptr\"]\n",
    "            indices = data[f\"pianoroll_{track_id}_csc_indices\"]\n",
    "\n",
    "            if f\"pianoroll_{track_id}_csc_data\" in data:\n",
    "                values = data[f\"pianoroll_{track_id}_csc_data\"]\n",
    "            else:\n",
    "                values = np.ones_like(indices, dtype=np.uint8)\n",
    "\n",
    "            sparse = csc_matrix((values, indices, indptr), shape=shape)\n",
    "            dense = sparse.toarray()\n",
    "            tracks[track_id] = dense\n",
    "\n",
    "    return tracks\n",
    "\n",
    "def plot_all_tracks(tracks_dict):\n",
    "    \"\"\"\n",
    "    Plot all tracks in the same figure, stacked vertically.\n",
    "    Each track is shown as a separate pianoroll.\n",
    "    \"\"\"\n",
    "    num_tracks = len(tracks_dict)\n",
    "    fig, axes = plt.subplots(num_tracks, 1, figsize=(12, 2.5 * num_tracks), sharex=True)\n",
    "\n",
    "    if num_tracks == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (track_id, pianoroll) in enumerate(sorted(tracks_dict.items())):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(pianoroll.T, aspect='auto', origin='lower', cmap='Greys')\n",
    "        ax.set_title(f\"Track {track_id}\")\n",
    "        ax.set_ylabel(\"Pitch\")\n",
    "        ax.set_xlabel(\"Time step\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c672d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"../midi/ea04f8ebe8f52d78ab6ce59d9ba04d20.npz\"\n",
    "\n",
    "tracks = load_all_tracks_from_npz(npz_path)\n",
    "plot_all_tracks(tracks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"../midi/98f90636c139256f4b7dade28ab87088.npz\"\n",
    "\n",
    "tracks = load_all_tracks_from_npz(npz_path)\n",
    "plot_all_tracks(tracks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
