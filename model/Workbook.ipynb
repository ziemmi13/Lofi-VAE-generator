{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a329471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\pretty_midi\\instrument.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from train import train\n",
    "from lofi_model import LofiModel\n",
    "from dataset import MidiDataset\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "from config import *\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffbd5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 88, 1754]) 1754 71\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "dataset = MidiDataset(dataset_dir=r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\")\n",
    "d1, d2, d3 = dataset[1][0],dataset[1][1], dataset[1][2]\n",
    "print(d1.shape, d2, d3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dcb974",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ebbf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Setting up datasets and dataloaders...\n",
      "Finished setting up datasets and dataloaders.\n",
      "Starting training:\n",
      "The datset has 2517 batches\n",
      "Epoch [1/500]\n",
      "Batch index: 1/2517\n",
      "Current training Loss: 23025.2324\n",
      "Batch index: 101/2517\n",
      "Current training Loss: 174926.6781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m model.to(device)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./saved_models/multitrack LSTM-VAE.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\model\\train.py:28\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataset_dir, verbose, model_save_path)\u001b[39m\n\u001b[32m     25\u001b[39m train_loss_KL = \u001b[32m0\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbpm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\model\\dataset.py:53\u001b[39m, in \u001b[36mMidiDataset.__getitem__\u001b[39m\u001b[34m(self, index, verbose)\u001b[39m\n\u001b[32m     50\u001b[39m file_path = os.path.join(\u001b[38;5;28mself\u001b[39m.songs_dir, file_name)\n\u001b[32m     51\u001b[39m bpm = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m.df.iloc[index, \u001b[32m3\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m pianoroll_tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_pianoroll_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m seq_len = pianoroll_tensor.shape[\u001b[32m2\u001b[39m]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\model\\dataset.py:75\u001b[39m, in \u001b[36mMidiDataset._prepare_pianoroll_tensor\u001b[39m\u001b[34m(self, file_path)\u001b[39m\n\u001b[32m     73\u001b[39m pianorolls = {instrument: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.valid_instruments}\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m midi_file.instruments:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     pianoroll = \u001b[43minstrument\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_piano_roll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFS\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     77\u001b[39m     instrument_category = \u001b[38;5;28mself\u001b[39m.get_midi_instrument_name(instrument)\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# Fill the dict with PRESENT instruments\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\venv\\Lib\\site-packages\\pretty_midi\\instrument.py:110\u001b[39m, in \u001b[36mInstrument.get_piano_roll\u001b[39m\u001b[34m(self, fs, times, pedal_threshold)\u001b[39m\n\u001b[32m    108\u001b[39m     end_time = times[-\u001b[32m1\u001b[39m]\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Allocate a matrix of zeros - we will add in as we go\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m piano_roll = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m*\u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Drum tracks don't have pitch, so return a matrix of zeros\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_drum:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "    # Dataset setup\n",
    "    dataset_dir = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\"\n",
    "\n",
    "    # Model setup\n",
    "    model = LofiModel(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Train\n",
    "    train(model, \n",
    "          dataset_dir, \n",
    "          verbose=True, \n",
    "          model_save_path = \"./saved_models/multitrack LSTM-VAE.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c883c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = LofiModel(device)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"saved_models/LSTM-VAE (velocity)#1.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cad895",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\"\n",
    "dataset = MidiDataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab87ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sequence_tensor, original_length_val, file_path = dataset[11]\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = model.reconstruct(original_sequence_tensor)\n",
    "reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffdd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a51dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db395df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\"\n",
    "dataset = MidiDataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e38cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sequence_tensor, original_length_val, file_path = dataset[10]\n",
    "original_sequence_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20235835",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_original_sequence, original_length_tensor = MidiDataset.collate_fn([(original_sequence_tensor, original_length_val)])\n",
    "padded_original_sequence = padded_original_sequence.to(device)\n",
    "padded_original_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_sample, _, _ = model(padded_original_sequence, original_length_tensor)\n",
    "reconstructed_sample = reconstructed_sample.squeeze()\n",
    "reconstructed_sample = torch.sigmoid(reconstructed_sample)\n",
    "reconstructed_sample[reconstructed_sample < 0.5] = 0\n",
    "reconstructed_sample[reconstructed_sample >= 0.5] = 1\n",
    "reconstructed_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_sample_T = reconstructed_sample.T\n",
    "reconstructed_sample_T.shape\n",
    "reconstructed_sample_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e016b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PrettyMIDI object\n",
    "midi = pretty_midi.PrettyMIDI()\n",
    "piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "piano = pretty_midi.Instrument(program=piano_program)\n",
    "\n",
    "# Track note on/off times per pitch\n",
    "# We'll detect note start and end by scanning through time steps\n",
    "for pitch_idx in range(reconstructed_sample_T.shape[0]):\n",
    "    note_on = None\n",
    "    for t in range(reconstructed_sample_T.shape[1]):\n",
    "        if reconstructed_sample_T[pitch_idx, t] == 1 and note_on is None:\n",
    "            # Note on at time t/fs seconds\n",
    "            note_on = t / FS\n",
    "        elif (reconstructed_sample_T[pitch_idx, t] == 0 or t == reconstructed_sample_T.shape[0]-1) and note_on is not None:\n",
    "            # Note off at time t/fs seconds\n",
    "            note_off = t / FS\n",
    "            # Add the note to the instrument\n",
    "            note = pretty_midi.Note(    \n",
    "                velocity=50,\n",
    "                pitch= pitch_idx+MIN_MIDI_NOTE,\n",
    "                start=note_on,\n",
    "                end=note_off\n",
    "            )\n",
    "            piano.notes.append(note)\n",
    "            note_on = None  # reset for next note\n",
    "\n",
    "    # If a note is still on at the end, close it\n",
    "    if note_on is not None:\n",
    "        note_off = reconstructed_sample_T.shape[1] / FS\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=50,\n",
    "            pitch= pitch_idx+MIN_MIDI_NOTE,\n",
    "            start=note_on,\n",
    "            end=note_off\n",
    "        )\n",
    "        piano.notes.append(note)\n",
    "\n",
    "# Add instrument to the PrettyMIDI object\n",
    "midi.instruments.append(piano)\n",
    "\n",
    "# Write out the MIDI data\n",
    "midi.write(\"1 4 6 5 - chord progression-RECONSTRUCTION.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ae2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a001b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3a6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c328b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d0e1618",
   "metadata": {},
   "source": [
    "# CHORD EXTRACTOR DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter\n",
    "\n",
    "midi_pth = r\"C:\\Users\\Hyperbook\\Desktop\\STUDIA\\SEM III\\Projekt zespolowy\\dataset\\1 2 6 - chord progression.mid\"\n",
    "midi_file = converter.parse(midi_pth)\n",
    "\n",
    "chords = midi_file.chordify()\n",
    "\n",
    "chord_progression = []\n",
    "\n",
    "for c in chords.flat.getElementsByClass(\"Chord\"):\n",
    "    if not c.isRest:\n",
    "        root_note = c.root().name\n",
    "        quality = c.quality\n",
    "        full_chord_name = c.pitchedCommonName\n",
    "        offset = c.offset  \n",
    "\n",
    "        chord_progression.append([root_note, quality, full_chord_name, offset])\n",
    "\n",
    "chord_progression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.load(\"../midi/98f90636c139256f4b7dade28ab87088.npz\")\n",
    "print(array)\n",
    "for a in array.keys():\n",
    "    print(a)\n",
    "    print(array[a])\n",
    "    print(20*\"___\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_all_tracks_from_npz(npz_path):\n",
    "    \"\"\"\n",
    "    Load all sparse pianoroll tracks from an LPD .npz file into dense arrays.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, np.ndarray]: Mapping from track_id to dense pianoroll (shape: time x pitch)\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    tracks = {}\n",
    "\n",
    "    for key in data.files:\n",
    "        if key.endswith(\"_csc_shape\"):\n",
    "            track_id = int(key.split(\"_\")[1])\n",
    "            shape = data[f\"pianoroll_{track_id}_csc_shape\"]\n",
    "            indptr = data[f\"pianoroll_{track_id}_csc_indptr\"]\n",
    "            indices = data[f\"pianoroll_{track_id}_csc_indices\"]\n",
    "\n",
    "            if f\"pianoroll_{track_id}_csc_data\" in data:\n",
    "                values = data[f\"pianoroll_{track_id}_csc_data\"]\n",
    "            else:\n",
    "                values = np.ones_like(indices, dtype=np.uint8)\n",
    "\n",
    "            sparse = csc_matrix((values, indices, indptr), shape=shape)\n",
    "            dense = sparse.toarray()\n",
    "            tracks[track_id] = dense\n",
    "\n",
    "    return tracks\n",
    "\n",
    "def plot_all_tracks(tracks_dict):\n",
    "    \"\"\"\n",
    "    Plot all tracks in the same figure, stacked vertically.\n",
    "    Each track is shown as a separate pianoroll.\n",
    "    \"\"\"\n",
    "    num_tracks = len(tracks_dict)\n",
    "    fig, axes = plt.subplots(num_tracks, 1, figsize=(12, 2.5 * num_tracks), sharex=True)\n",
    "\n",
    "    if num_tracks == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (track_id, pianoroll) in enumerate(sorted(tracks_dict.items())):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(pianoroll.T, aspect='auto', origin='lower', cmap='Greys')\n",
    "        ax.set_title(f\"Track {track_id}\")\n",
    "        ax.set_ylabel(\"Pitch\")\n",
    "        ax.set_xlabel(\"Time step\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c672d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"../midi/ea04f8ebe8f52d78ab6ce59d9ba04d20.npz\"\n",
    "\n",
    "tracks = load_all_tracks_from_npz(npz_path)\n",
    "plot_all_tracks(tracks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"../midi/98f90636c139256f4b7dade28ab87088.npz\"\n",
    "\n",
    "tracks = load_all_tracks_from_npz(npz_path)\n",
    "plot_all_tracks(tracks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
